{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9j8T/EZIyX+Xa7NFnhI91",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaeohshin/deep-learning-with-keras/blob/main/tutorial_8_naturla_languate_process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UijWfxXS5db8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naturla Language Process (NLP)"
      ],
      "metadata": {
        "id": "Xbox-bGE-2x9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sriHDzS4-8M4",
        "outputId": "cbf5c960-9d70-4869-8e1a-1e60422ac786"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  72.5M      0  0:00:01  0:00:01 --:--:-- 72.4M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "id": "1EVh-TS3_jP5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd aclImdb/\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5np76ua_1_h",
        "outputId": "74b26fc4-9bf3-4efe-f6b1-a156f8a861c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDT_w5iJ_-38",
        "outputId": "ea1d7008-f046-496d-f4dd-60bb09a989db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aclImdb  aclImdb_v1.tar.gz  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd aclImdb/"
      ],
      "metadata": {
        "id": "f1X3qvUlAC0B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbDYE_3BAGpL",
        "outputId": "a2d372b9-ad28-409f-f67b-8d6e1540995f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXgMFgiqAIGN",
        "outputId": "803f1919-b8d8-4755-9cf6-65a50df41dfc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "id": "k24PgTwjASrE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat aclImdb/train/pos/4077_10.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcAlvObmAYc1",
        "outputId": "9e559e5e-7d9c-4aaa-e54d-fbb269a3f036"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare a validation set by setting aprt 20% of the training text file\n",
        "#in a new directory, /val\n",
        "\n",
        "import os, pathlib, shutil, random\n",
        "\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(val_dir / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)\n",
        "    num_val_samples = int(0.2 * len(files))\n",
        "    val_files = files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "        # move files from train dir to val dir, this means the files in the\n",
        "        # train can be reduced by 20%.\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)\n",
        ""
      ],
      "metadata": {
        "id": "PPs53W3qAqZM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create three data sets for training, validation, and testing\n",
        "from tensorflow import keras\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size = batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size = batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size = batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5ASc_3mLAju",
        "outputId": "402d1b8f-dba5-4c01-af6d-ec32aed57174"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[100]:\", inputs[0])\n",
        "    print(\"targets[100]:\", targets[0])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H1IltPhMmCZ",
        "outputId": "314bbc9b-83f9-4e5d-88b6-ed72dce5b3ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[100]: tf.Tensor(b'This film is something like a sequel of \"White Zombie\", since it is made by the same man (Halperin) and features zombies. Halperin, the George A. Romero of his day, fails to deliver with this one, though.<br /><br />We have a man who can control the minds of people in Cambodia, and a search to destroy the source of his power so the zombies can be sent free. Also, a love interest for the evil man.<br /><br />Where this film really excels is in the imagery. The Cambodian temples and dancers are very nice and the zombie look very powerful in their large numbers. Unfortunately, we don\\'t really get to see much of the zombies in action and the love story seems to play a much too large role for a horror film (though this has a valid plot reason later on).<br /><br />I would have loved to see some 1930s zombies attack helpless city folk, but this film just did not deliver. And no strong villain (like Bela Lugosi) was waiting to do battle against our heroes. And the use of Lugosi\\'s eyes? A nice effect, but misleading as he is never in the film... why not recreate this with the new actor\\'s eyes? Overall, a film that could be a great one with a little script re-working and could someday be a powerful remake (especially if they keep it in the same post-war time frame). Heck, if they can fix up \"The Hills Have Eyes\" then this film has hope.', shape=(), dtype=string)\n",
            "targets[100]: tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",\n",
        ")"
      ],
      "metadata": {
        "id": "r3KTv_Q0VLjv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Processing words as a set- bag-of-words approach\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")\n",
        "\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "binary_1gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "binary_1gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "binary_1gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "q1p_0n7eOCHj"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in binary_1gram_train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtyp:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SglhLlRiV1AT",
        "outputId": "0dcfc612-b950-4a3d-9195-96952e842813"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32, 20000)\n",
            "inputs.dtyp: <dtype: 'float32'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model build\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model(max_tokens=20000, hidden_dim = 16):\n",
        "    inputs = keras.Input(shape = (max_tokens,))\n",
        "    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "NSumAkhRWtr0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test the model\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(binary_1gram_train_ds.cache(),\n",
        "          validation_data=binary_1gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"binary_1gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTG3hPZTXfW1",
        "outputId": "e51b5605-cefe-4c66-c2a0-9cb7ba292c9e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 11s 10ms/step - loss: 0.4251 - accuracy: 0.8180 - val_loss: 0.2988 - val_accuracy: 0.8808\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2851 - accuracy: 0.8949 - val_loss: 0.2881 - val_accuracy: 0.8882\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2492 - accuracy: 0.9103 - val_loss: 0.3031 - val_accuracy: 0.8830\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2290 - accuracy: 0.9192 - val_loss: 0.3258 - val_accuracy: 0.8800\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2227 - accuracy: 0.9244 - val_loss: 0.3408 - val_accuracy: 0.8826\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2111 - accuracy: 0.9302 - val_loss: 0.3505 - val_accuracy: 0.8794\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2053 - accuracy: 0.9322 - val_loss: 0.3930 - val_accuracy: 0.8652\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2022 - accuracy: 0.9362 - val_loss: 0.3833 - val_accuracy: 0.8742\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1991 - accuracy: 0.9368 - val_loss: 0.3922 - val_accuracy: 0.8728\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2025 - accuracy: 0.9359 - val_loss: 0.3999 - val_accuracy: 0.8722\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.2901 - accuracy: 0.8861\n",
            "Test acc: 0.886\n"
          ]
        }
      ]
    }
  ]
}