{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5ihyCbToQWsbD11XwIxeV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaeohshin/deep-learning-with-keras/blob/main/tutorial_8_naturla_languate_process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naturla Language Process (NLP)"
      ],
      "metadata": {
        "id": "Xbox-bGE-2x9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sriHDzS4-8M4",
        "outputId": "ce86e598-fec6-478d-9e43-cddb480eb548"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  34.3M      0  0:00:02  0:00:02 --:--:-- 34.3M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "id": "1EVh-TS3_jP5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd aclImdb/\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5np76ua_1_h",
        "outputId": "0e8d7206-425c-4d0a-9d57-22168428d9c9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDT_w5iJ_-38",
        "outputId": "07e4b0f3-d028-45ef-fe99-e27bd7aae5c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aclImdb  aclImdb_v1.tar.gz  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd aclImdb/"
      ],
      "metadata": {
        "id": "f1X3qvUlAC0B"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbDYE_3BAGpL",
        "outputId": "7f198fa5-6dca-403d-865d-0ccbaea89bb0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXgMFgiqAIGN",
        "outputId": "8baddfa6-6320-4b30-82a9-9efe2a551043"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "id": "k24PgTwjASrE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat aclImdb/train/pos/4077_10.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcAlvObmAYc1",
        "outputId": "06a717f2-2c7a-4bbf-d556-860c83ddf7fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare a validation set by setting aprt 20% of the training text file\n",
        "#in a new directory, /val\n",
        "\n",
        "import os, pathlib, shutil, random\n",
        "\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(val_dir / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)\n",
        "    num_val_samples = int(0.2 * len(files))\n",
        "    val_files = files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "        # move files from train dir to val dir, this means the files in the\n",
        "        # train can be reduced by 20%.\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)\n"
      ],
      "metadata": {
        "id": "PPs53W3qAqZM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create three data sets for training, validation, and testing\n",
        "from tensorflow import keras\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size = batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size = batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size = batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5ASc_3mLAju",
        "outputId": "2b5814df-05a9-4b21-c82b-4d5b050a87d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[100]:\", inputs[0])\n",
        "    print(\"targets[100]:\", targets[0])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H1IltPhMmCZ",
        "outputId": "c2f4f9d5-de44-48a8-d318-56e463b36917"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[100]: tf.Tensor(b'With the death of GEORGE NADER, on 4 February 2002, I thought of this most interesting program, which even though it had only a short run, was a tremendous idea with good story lines throughout. Generally unseen for over 40+ years it would be worth viewing again. The opening credits showed many differing images, one of which was a snippit of COLONEL JOHN PAUL STAPP, riding his famed rocket sled, at the point where he was often referred to as \"The Fastest Man Alive\".', shape=(), dtype=string)\n",
            "targets[100]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",\n",
        ")"
      ],
      "metadata": {
        "id": "r3KTv_Q0VLjv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Processing words as a set- bag-of-words approach\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")\n",
        "\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "binary_1gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "binary_1gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "binary_1gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "q1p_0n7eOCHj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in binary_1gram_train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtyp:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SglhLlRiV1AT",
        "outputId": "b92c14e5-f180-48c1-99c8-7b5cec4eae5e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32, 20000)\n",
            "inputs.dtyp: <dtype: 'float32'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model build\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model(max_tokens=20000, hidden_dim = 16):\n",
        "    inputs = keras.Input(shape = (max_tokens,))\n",
        "    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "NSumAkhRWtr0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test the model\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(binary_1gram_train_ds.cache(),\n",
        "          validation_data=binary_1gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"binary_1gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTG3hPZTXfW1",
        "outputId": "098924d9-be2b-471e-892e-63688c9a21fd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 10s 8ms/step - loss: 0.4049 - accuracy: 0.8292 - val_loss: 0.2915 - val_accuracy: 0.8830\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2712 - accuracy: 0.8992 - val_loss: 0.2898 - val_accuracy: 0.8844\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.2381 - accuracy: 0.9150 - val_loss: 0.3050 - val_accuracy: 0.8846\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.2309 - accuracy: 0.9205 - val_loss: 0.3152 - val_accuracy: 0.8838\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2201 - accuracy: 0.9261 - val_loss: 0.3317 - val_accuracy: 0.8832\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2188 - accuracy: 0.9294 - val_loss: 0.3392 - val_accuracy: 0.8840\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2048 - accuracy: 0.9324 - val_loss: 0.3549 - val_accuracy: 0.8826\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2102 - accuracy: 0.9360 - val_loss: 0.3461 - val_accuracy: 0.8836\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2010 - accuracy: 0.9360 - val_loss: 0.3601 - val_accuracy: 0.8746\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9341 - val_loss: 0.3674 - val_accuracy: 0.8794\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.2928 - accuracy: 0.8837\n",
            "Test acc: 0.884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The above method shows the accuracy of 88%.\n"
      ],
      "metadata": {
        "id": "1JWPoC9CRPnb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gxprUQwlRVFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Below I'll use Bigrams."
      ],
      "metadata": {
        "id": "qdNSQB0qRy5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")"
      ],
      "metadata": {
        "id": "5Cl9OhxJR4Dy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization.adapt(text_only_train_ds)\n",
        "binary_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(binary_2gram_train_ds.cache(),\n",
        "          validation_data=binary_2gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"binary_2gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "id": "3NpuaqnGTG5T",
        "outputId": "1c926d9c-8343-4ddb-b45f-d2eb3fe356fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.3791 - accuracy: 0.8439 - val_loss: 0.2715 - val_accuracy: 0.8926\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2413 - accuracy: 0.9168 - val_loss: 0.2765 - val_accuracy: 0.8950\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.1992 - accuracy: 0.9312 - val_loss: 0.2917 - val_accuracy: 0.8960\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1869 - accuracy: 0.9403 - val_loss: 0.3019 - val_accuracy: 0.8960\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.1744 - accuracy: 0.9467 - val_loss: 0.3281 - val_accuracy: 0.8982\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1621 - accuracy: 0.9511 - val_loss: 0.3438 - val_accuracy: 0.8946\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1587 - accuracy: 0.9531 - val_loss: 0.3589 - val_accuracy: 0.8926\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1576 - accuracy: 0.9564 - val_loss: 0.3654 - val_accuracy: 0.8894\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1526 - accuracy: 0.9597 - val_loss: 0.3822 - val_accuracy: 0.8884\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1465 - accuracy: 0.9584 - val_loss: 0.3835 - val_accuracy: 0.8868\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.2658 - accuracy: 0.8978\n",
            "Test acc: 0.898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams = 2,\n",
        "    max_tokens = 20000,\n",
        "    output_mode = \"tf_idf\"\n",
        ")"
      ],
      "metadata": {
        "id": "AV0Z_9VRTovZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "tfidf_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "tfidf_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "tfidf_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"tfidf_2gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "\n",
        "model.fit(tfidf_2gram_train_ds.cache(),\n",
        "          validation_data = tfidf_2gram_val_ds.cache(),\n",
        "          epochs = 10,\n",
        "          callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\"tfidf_2gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")\n"
      ],
      "metadata": {
        "id": "mrH-9CG-T8sS",
        "outputId": "823c379d-b745-439a-a79c-022fbcafcceb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5077 - accuracy: 0.7666 - val_loss: 0.3180 - val_accuracy: 0.8712\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.3416 - accuracy: 0.8490 - val_loss: 0.3220 - val_accuracy: 0.8740\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.3039 - accuracy: 0.8676 - val_loss: 0.3294 - val_accuracy: 0.8818\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.2766 - accuracy: 0.8797 - val_loss: 0.3828 - val_accuracy: 0.8554\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2680 - accuracy: 0.8848 - val_loss: 0.3545 - val_accuracy: 0.8772\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2444 - accuracy: 0.8916 - val_loss: 0.3666 - val_accuracy: 0.8714\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2448 - accuracy: 0.8924 - val_loss: 0.3985 - val_accuracy: 0.8728\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2412 - accuracy: 0.8956 - val_loss: 0.4328 - val_accuracy: 0.8626\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2328 - accuracy: 0.9005 - val_loss: 0.4015 - val_accuracy: 0.8704\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.2323 - accuracy: 0.9028 - val_loss: 0.4124 - val_accuracy: 0.8620\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.3131 - accuracy: 0.8710\n",
            "Test acc: 0.871\n"
          ]
        }
      ]
    }
  ]
}